# 설계도: 1단계 (토크나이저) - 3. 단일 문자 연산자 토큰화 테스트 및 구현

**목표:** `Lexer`가 덧셈(`+`), 뺄셈(`-`), 곱셈(`*`), 나눗셈(`/`)과 같은 기본적인 단일 문자 산술 연산자를 인식하고, 각각에 해당하는 정확한 토큰 타입과 리터럴로 토큰을 생성하도록 합니다. 할당 연산자(`=`)와 기타 비교 연산자(`<`, `>`), 느낌표(`!`) 등도 이 단계에서 함께 처리합니다.

**이행 절차:**

1.  **단일 문자 연산자 토큰화 테스트 케이스 추가:**
    *   작업: `interpreter/lexer_test.go` 파일의 `TestNextToken_Operators` (또는 새로 생성) 테스트 함수에 다음 입력과 예상 토큰 시퀀스를 포함하는 테스트 케이스들을 추가합니다:
        *   입력: `"+-*/"`
            *   예상: `PLUS("+")`, `MINUS("-")`, `ASTERISK("*")`, `SLASH("/")`, `EOF("")`
        *   입력: `"= < > !"` (공백 포함)
            *   예상: `ASSIGN("=")`, `LT("<")`, `GT(">")`, `BANG("!")`, `EOF("")`
        *   입력: `+ - = * / < > !` (다양한 단일 연산자 혼합)
            *   예상: 각 연산자에 맞는 토큰들과 마지막 `EOF`
    *   확인: 테스트 케이스가 다양한 단일 문자 연산자를 포함하고, 각 연산자에 대해 올바른 `TokenType`과 해당 문자 리터럴을 가진 `Token`을 기대하는지 확인합니다. 이중 문자 연산자(==, !=)는 이 단계에서 다루지 않습니다.
2.  **`NextToken()` 메서드에 단일 문자 연산자 처리 로직 추가:**
    *   작업: `interpreter/lexer.go`의 `NextToken()` 함수 내 `switch l.ch` 문에 다음 `case`들을 추가합니다:
        *   `case '=':`: `ASSIGN` 토큰 생성
        *   `case '+':`: `PLUS` 토큰 생성
        *   `case '-':`: `MINUS` 토큰 생성
        *   `case '*':`: `ASTERISK` 토큰 생성
        *   `case '/':`: `SLASH` 토큰 생성
        *   `case '<':`: `LT` 토큰 생성
        *   `case '>':`: `GT` 토큰 생성
        *   `case '!':`: `BANG` 토큰 생성
        *   각 `case`에서는 해당 `TokenType`과 `l.ch`를 문자열로 변환한 리터럴로 `Token`을 생성합니다.
    *   확인: 각 연산자 문자에 대해 올바른 토큰 타입이 매핑되었는지, 리터럴이 해당 문자로 설정되는지 확인합니다. `default` 케이스는 여전히 `ILLEGAL` 또는 다른 타입(식별자, 숫자 등) 처리 로직으로 연결됩니다.
3.  **연산자 토큰화 테스트 실행 (실패 및 성공 확인):**
    *   작업: `go test -v yak/interpreter -run TestNextToken_Operators` (또는 전체 테스트) 명령으로 테스트를 실행합니다.
    *   확인: 처음에는 `ILLEGAL` 토큰으로 처리되던 연산자들이 이제 올바른 연산자 토큰으로 생성되어 테스트가 통과하는지 확인합니다.
